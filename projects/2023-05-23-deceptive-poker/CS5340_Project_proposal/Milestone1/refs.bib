@article{marl:blog,
  title={How Modern Game Theory is Influencing Multi-Agent Reinforcement Learning Systems},
  author={Jesus Rodriguez},
  journal={Medium: Dataseries},
  year={2020}
}

@article{pomdp:blog,
  title={POMDP: Introduction to Partially Observable Markov Decision Processes},
  author={Michael Hahsler and Hossein Kamalzadeh},
  journal={https://cran.r-project.org/web/packages/pomdp/vignettes/POMDP.html},
  year={2021}
}

@article{dcfr:2018,
  title={Deep Counterfactual Regret Minimization},
  author={Brown, N., Lerer, A., Gross, S., & Sandholm, T.},
  journal={ArXiv. /abs/1811.00164},
  year={2018}
}

@article{rebel:2020,
  title={Combining Deep Reinforcement Learning and Search for Imperfect-Information Games},
  author={Brown, N., Bakhtin, A., Lerer, A., & Gong, Q.},
  journal={ArXiv. /abs/2007.13544},
  year={2020}
}

@misc{lowerbound,
      title={Equilibrium Approximation Quality of Current No-Limit Poker Bots}, 
      author={Viliam Lisy and Michael Bowling},
      year={2017},
      eprint={1612.07547},
      archivePrefix={arXiv},
      primaryClass={cs.GT}
}

@misc{br_ddqn,
      title={Dueling Network Architectures for Deep Reinforcement Learning}, 
      author={Ziyu Wang and Tom Schaul and Matteo Hessel and Hado van Hasselt and Marc Lanctot and Nando de Freitas},
      year={2016},
      eprint={1511.06581},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{nsfp:2016,
  title={Deep Reinforcement Learning from Self-Play in Imperfect-Information Games},
  author={Heinrich, J., & Silver, D.},
  journal={ArXiv. /abs/1603.01121},
  year={2016}
}

@article{openspiel:2019,
  title={OpenSpiel: A Framework for Reinforcement Learning in Games},
  author={Lanctot, M., Lockhart, E., Lespiau, J., Zambaldi, V., Upadhyay, S., Pérolat, J., Srinivasan, S., Timbers, F., Tuyls, K., Omidshafiei, S., Hennes, D., Morrill, D., Muller, P., Ewalds, T., Faulkner, R., Kramár, J., De Vylder, B., Saeta, B., Bradbury, J., . . .  Danihelka, I.},
  journal={ArXiv. /abs/1908.09453},
  year={2019}
}

@article{rlcard,
  title={RLCard: A Toolkit for Reinforcement Learning in Card Games},
  author={Zha, D., Lai, K., Cao, Y., Huang, S., Wei, R., Guo, J., & Hu, X.},
  journal={ArXiv. /abs/1910.04376},
  year={2019}
}

@article{maddpg,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Lowe, R., Wu, Y., Tamar, A., Harb, J., Abbeel, P., & Mordatch, I.},
  journal={ArXiv. /abs/1706.02275},
  year={2017}
}

@article{deepstack,
	doi = {10.1126/science.aam6960},
	url = {https://doi.org/10.1126%2Fscience.aam6960},
	year = 2017,
	month = {may},
	publisher = {American Association for the Advancement of Science ({AAAS})},
	volume = {356},
	number = {6337},
	pages = {508--513},
	author = {Matej Morav{\v{c}
}{\'{\i}}k and Martin Schmid and Neil Burch and Viliam Lis{\'{y}} and Dustin Morrill and Nolan Bard and Trevor Davis and Kevin Waugh and Michael Johanson and Michael Bowling},
	title = {{DeepStack}: Expert-level artificial intelligence in heads-up no-limit poker},
	journal = {Science}
}
